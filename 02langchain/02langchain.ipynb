{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02d15274",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好！我是一个人工智能助手，专门设计来帮助解答问题和提供信息。我可以协助你获取各种主题的资料，无论是科技、历史、文化还是日常生活等等。请随时向我提出问题，我会尽力为你提供帮助！', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 94, 'prompt_tokens': 14, 'total_tokens': 108, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-4', 'system_fingerprint': 'fp_5603ee5e2e', 'id': 'chatcmpl-CKlM8jJ8Ob39X0ydXaveDqOzKv4LV', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--3c77cbe2-544f-4fdf-a197-b3455e954efd-0', usage_metadata={'input_tokens': 14, 'output_tokens': 94, 'total_tokens': 108, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ChatOllama\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0,\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"), \n",
    "    base_url=os.getenv(\"OPENAI_API_BASE\")\n",
    ")\n",
    "llm.invoke(\"介绍你自己\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c4ed3bb-b907-4644-9cff-438146291eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是一个起名大师，请模仿示例起3个中国特色名字，比如：男孩经常被叫做狗剩,女孩经常被叫做翠花\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='男孩：铁柱、小强、石头\\n女孩：红梅、桂花、玉兰', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 66, 'total_tokens': 102, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-4', 'system_fingerprint': 'fp_5603ee5e2e', 'id': 'chatcmpl-CKl1R60RmwJksYfWBqskChYbUXHIG', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--c89fe63d-6688-44a2-9759-958037509deb-0', usage_metadata={'input_tokens': 66, 'output_tokens': 36, 'total_tokens': 102, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0,\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"), \n",
    "    base_url=os.getenv(\"OPENAI_API_BASE\")\n",
    ")\n",
    "prompt = PromptTemplate.from_template(\"你是一个起名大师，请模仿示例起3个{county}名字，比如：男孩经常被叫做{boy},女孩经常被叫做{girl}\")\n",
    "message=prompt.format(county=\"中国特色\", boy=\"狗剩\", girl=\"翠花\")\n",
    "print(message)\n",
    "\n",
    "llm.invoke(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe21c7c3-f14a-43ae-8d14-e0c92f37b29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是一个起名大师，请模仿示例起3个中国特色名字，比如：男孩经常被叫做狗剩,女孩经常被叫做翠花\n",
      "['当然可以！以下是三个具有中国特色的名字：\\n\\n1. 男孩：小虎\\n2. 女孩：梅花\\n3. 男孩：阿强\\n\\n这些名字都带有亲切感和传统色彩，符合中国特色的命名习惯。希望你喜欢！']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['当然可以！以下是三个具有中国特色的名字：\\n\\n1. 男孩：小虎\\n2. 女孩：梅花\\n3. 男孩：阿强\\n\\n这些名字都带有亲切感和传统色彩，符合中国特色的命名习惯。希望你喜欢！']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#起名大师，输出格式为一个数组\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import os\n",
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "#自定义类\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        if hasattr(text, 'content'):\n",
    "            text = text.content\n",
    "        t = text.strip().split(\",\")\n",
    "        print(t)\n",
    "        return t\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    temperature=0,\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"), \n",
    "    base_url=os.getenv(\"OPENAI_API_BASE\")\n",
    ")\n",
    "prompt = PromptTemplate.from_template(\"你是一个起名大师，请模仿示例起3个{county}名字，比如：男孩经常被叫做{boy},女孩经常被叫做{girl}\")\n",
    "message=prompt.format(county=\"中国广东特色\", boy=\"狗剩\", girl=\"翠花\")\n",
    "print(message)\n",
    "strs = llm.invoke(message)\n",
    "CommaSeparatedListOutputParser().parse(strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "259fe51d-8574-46cd-bb48-5f3945fbb0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始响应内容: 当然可以！以下是三个具有中国特色的名字：\n",
      "\n",
      "1. 男孩：小虎\n",
      "2. 女孩：梅花\n",
      "3. 男孩：阿强\n",
      "\n",
      "这些名字都带有一定的亲切感和传统色彩。希望你喜欢！\n",
      "解析后结果: ['当然可以！以下是三个具有中国特色的名字：\\n\\n1. 男孩：小虎\\n2. 女孩：梅花\\n3. 男孩：阿强\\n\\n这些名字都带有一定的亲切感和传统色彩。希望你喜欢！']\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI  # 确保正确导入 ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "\n",
    "# 自定义解析器\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    def parse(self, text):\n",
    "        if hasattr(text, 'content'):\n",
    "            text = text.content\n",
    "        return text.strip().split(\",\")\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "# 初始化 LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    temperature=0,\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"), \n",
    "    base_url=os.getenv(\"OPENAI_API_BASE\")\n",
    ")\n",
    " \n",
    "# 创建提示模板\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"你是一个起名大师，请模仿示例起3个{county}名字，比如：男孩经常被叫做{boy},女孩经常被叫做{girl}\"\n",
    ")\n",
    " \n",
    "# 生成具体输入\n",
    "message = prompt.format(\n",
    "    county=\"中国特色\",\n",
    "    boy=\"狗剩\",\n",
    "    girl=\"翠花\"\n",
    ")\n",
    " \n",
    "# 调用 LLM 并解析结果\n",
    "response = llm.invoke(message)\n",
    "parsed_result = CommaSeparatedListOutputParser().parse(response)\n",
    " \n",
    "print(\"原始响应内容:\", response.content)\n",
    "print(\"解析后结果:\", parsed_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "865648e0-2119-42d9-9414-8831a7c5ff01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event=on_chat_model_start | name=ChatOpenAI | data={'input': '介绍langchain'}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='Lang', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='Chain', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='是', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='一个', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='开', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='源', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='的', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='自', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='然', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='语', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='言', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='处理', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='（', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='N', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='LP', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='）', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='框', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='架', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='，', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='专', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='注', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='于', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='构', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='建', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='和', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='部', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='署', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='基', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='于', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='语', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='言', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='的', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='应', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='用', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='程序', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='。', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='它', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='提', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='供', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='了', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='一', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='系', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='列', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='工', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='具', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='和', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='库', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='，', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='使', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='开', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='发', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='者', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='能', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='够', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='轻', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='松', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='地', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='创建', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='、', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='训', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='练', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='和', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='部', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='署', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='与', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='人', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='类', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='进行', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='交', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='互', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='的', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='语', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='言', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='模', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='型', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='。', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='Lang', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='Chain', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='的', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='目', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='标', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='是', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='简', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='化', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='N', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='LP', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='应', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='用', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='的', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='开', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='发', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='过', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='程', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='，', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='使', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='其', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='更', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='加', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='高', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='效', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='和', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='可', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='扩', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='展', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='。', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='它', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='支', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='持', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='多', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='种', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='语', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='言', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='和', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='框', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='架', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='，', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='使', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='得', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='开', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='发', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='者', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='可以', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='根', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='据', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='自', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='己', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='的', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='需', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='求', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='选择', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='最', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='合', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='适', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='的', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='工', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='具', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='。', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4', 'system_fingerprint': 'fp_5603ee5e2e'}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 12, 'output_tokens': 155, 'total_tokens': 167, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_end | name=ChatOpenAI | data={'output': AIMessageChunk(content='LangChain是一个开源的自然语言处理（NLP）框架，专注于构建和部署基于语言的应用程序。它提供了一系列工具和库，使开发者能够轻松地创建、训练和部署与人类进行交互的语言模型。LangChain的目标是简化NLP应用的开发过程，使其更加高效和可扩展。它支持多种语言和框架，使得开发者可以根据自己的需求选择最合适的工具。', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4', 'system_fingerprint': 'fp_5603ee5e2e'}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 12, 'output_tokens': 155, 'total_tokens': 167, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import asyncio\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0,\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    base_url=os.environ.get(\"OPENAI_API_BASE\"),\n",
    ")\n",
    "question=\"langchain是什么？\"\n",
    "\n",
    "# invoke事件，同步调用LLM处理单个输入，返回完整响应。\n",
    "# llm.invoke(question)\n",
    "\n",
    "# stream事件，同步流式返回LLM的响应块（tokens），支持实时输出。\n",
    "# for chunk in llm.stream(question):\n",
    "#     print(chunk.content + \"|\")\n",
    "\n",
    "# batch 事件，批量处理多个输入，返回结果列表。\n",
    "# llm.batch([\"langchain作者是谁？\", \"langchain竞品有哪些？\"])\n",
    "\n",
    "# 异步事件流 astream_events。异步流式返回LLM执行过程中的事件（如开始、结束、中间步骤）。\n",
    "async for event in llm.astream_events(\"介绍langchain\", version=\"v2\"):\n",
    "    print(f\"event={event['event']} | name={event['name']} | data={event['data']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9d05153-861e-4e2f-9b5b-55ac9a7c684d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='Why do programmers prefer dark mode?', punchline='Because light attracts bugs!', rating=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    temperature=0,\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    base_url=os.environ.get(\"OPENAI_API_BASE\"),\n",
    "    )\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline to the joke\")\n",
    "    rating: Optional[int] = Field(\n",
    "        default=None, description=\"How funny the joke is, from 1 to 10\"\n",
    "    )\n",
    "structured_llm = llm.with_structured_output(Joke, method=\"function_calling\")\n",
    "structured_llm.invoke(\"给我讲一个关于程序员的笑话\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75c29092-f624-488e-91f8-a748f16f36ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'setup': ''}\n",
      "{'setup': '为'}\n",
      "{'setup': '为什'}\n",
      "{'setup': '为什么'}\n",
      "{'setup': '为什么程序'}\n",
      "{'setup': '为什么程序员'}\n",
      "{'setup': '为什么程序员喜'}\n",
      "{'setup': '为什么程序员喜欢'}\n",
      "{'setup': '为什么程序员喜欢黑'}\n",
      "{'setup': '为什么程序员喜欢黑暗'}\n",
      "{'setup': '为什么程序员喜欢黑暗？'}\n",
      "{'setup': '为什么程序员喜欢黑暗？', 'punchline': ''}\n",
      "{'setup': '为什么程序员喜欢黑暗？', 'punchline': '因'}\n",
      "{'setup': '为什么程序员喜欢黑暗？', 'punchline': '因为'}\n",
      "{'setup': '为什么程序员喜欢黑暗？', 'punchline': '因为光'}\n",
      "{'setup': '为什么程序员喜欢黑暗？', 'punchline': '因为光会'}\n",
      "{'setup': '为什么程序员喜欢黑暗？', 'punchline': '因为光会产'}\n",
      "{'setup': '为什么程序员喜欢黑暗？', 'punchline': '因为光会产生'}\n",
      "{'setup': '为什么程序员喜欢黑暗？', 'punchline': '因为光会产生bug'}\n",
      "{'setup': '为什么程序员喜欢黑暗？', 'punchline': '因为光会产生bug！'}\n"
     ]
    }
   ],
   "source": [
    "from typing_extensions import Annotated, TypedDict\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import Optional, Union\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    temperature=0,\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    base_url=os.environ.get(\"OPENAI_API_BASE\"),\n",
    "    )\n",
    "\n",
    "class Joke(TypedDict):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "    setup: Annotated[str, ..., \"the setup of the joke\"]\n",
    "    punchline: Annotated[str, ..., \"The punchline of the joke\"]\n",
    "    rating: Annotated[Optional[int], None, \"How funny the joke is, from 1 to 10\"]\n",
    "\n",
    "structured_llm = llm.with_structured_output(Joke, method=\"function_calling\")\n",
    "for chunk in structured_llm.stream(\"给我讲一个关于程序员的笑话\"):\n",
    "    print(chunk)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b961d642-95c2-456f-9fa3-db245af793a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'message': 'Not found', 'type': 'invalid_request_error'}}",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNotFoundError\u001B[39m                             Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 27\u001B[39m\n\u001B[32m     25\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[32m5\u001B[39m):\n\u001B[32m     26\u001B[39m     tic = time.time()\n\u001B[32m---> \u001B[39m\u001B[32m27\u001B[39m     \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mhello\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     28\u001B[39m     toc = time.time()\n\u001B[32m     29\u001B[39m     \u001B[38;5;28mprint\u001B[39m(toc - tic)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\github\\llm\\02langchain\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:395\u001B[39m, in \u001B[36mBaseChatModel.invoke\u001B[39m\u001B[34m(self, input, config, stop, **kwargs)\u001B[39m\n\u001B[32m    383\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m    384\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minvoke\u001B[39m(\n\u001B[32m    385\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    390\u001B[39m     **kwargs: Any,\n\u001B[32m    391\u001B[39m ) -> BaseMessage:\n\u001B[32m    392\u001B[39m     config = ensure_config(config)\n\u001B[32m    393\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(\n\u001B[32m    394\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mChatGeneration\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m--> \u001B[39m\u001B[32m395\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgenerate_prompt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    396\u001B[39m \u001B[43m            \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_convert_input\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    397\u001B[39m \u001B[43m            \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    398\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcallbacks\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    399\u001B[39m \u001B[43m            \u001B[49m\u001B[43mtags\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtags\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    400\u001B[39m \u001B[43m            \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmetadata\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    401\u001B[39m \u001B[43m            \u001B[49m\u001B[43mrun_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrun_name\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    402\u001B[39m \u001B[43m            \u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrun_id\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    403\u001B[39m \u001B[43m            \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    404\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m.generations[\u001B[32m0\u001B[39m][\u001B[32m0\u001B[39m],\n\u001B[32m    405\u001B[39m     ).message\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\github\\llm\\02langchain\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1023\u001B[39m, in \u001B[36mBaseChatModel.generate_prompt\u001B[39m\u001B[34m(self, prompts, stop, callbacks, **kwargs)\u001B[39m\n\u001B[32m   1014\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m   1015\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mgenerate_prompt\u001B[39m(\n\u001B[32m   1016\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1020\u001B[39m     **kwargs: Any,\n\u001B[32m   1021\u001B[39m ) -> LLMResult:\n\u001B[32m   1022\u001B[39m     prompt_messages = [p.to_messages() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[32m-> \u001B[39m\u001B[32m1023\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt_messages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\github\\llm\\02langchain\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:840\u001B[39m, in \u001B[36mBaseChatModel.generate\u001B[39m\u001B[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[39m\n\u001B[32m    837\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i, m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(input_messages):\n\u001B[32m    838\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    839\u001B[39m         results.append(\n\u001B[32m--> \u001B[39m\u001B[32m840\u001B[39m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_generate_with_cache\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    841\u001B[39m \u001B[43m                \u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    842\u001B[39m \u001B[43m                \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    843\u001B[39m \u001B[43m                \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    844\u001B[39m \u001B[43m                \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    845\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    846\u001B[39m         )\n\u001B[32m    847\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    848\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\github\\llm\\02langchain\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1089\u001B[39m, in \u001B[36mBaseChatModel._generate_with_cache\u001B[39m\u001B[34m(self, messages, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m   1087\u001B[39m     result = generate_from_stream(\u001B[38;5;28miter\u001B[39m(chunks))\n\u001B[32m   1088\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m inspect.signature(\u001B[38;5;28mself\u001B[39m._generate).parameters.get(\u001B[33m\"\u001B[39m\u001B[33mrun_manager\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m-> \u001B[39m\u001B[32m1089\u001B[39m     result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_generate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1090\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m   1091\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1092\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1093\u001B[39m     result = \u001B[38;5;28mself\u001B[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\github\\llm\\02langchain\\.venv\\Lib\\site-packages\\langchain_anthropic\\chat_models.py:1760\u001B[39m, in \u001B[36mChatAnthropic._generate\u001B[39m\u001B[34m(self, messages, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m   1758\u001B[39m payload = \u001B[38;5;28mself\u001B[39m._get_request_payload(messages, stop=stop, **kwargs)\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1760\u001B[39m     data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_create\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpayload\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1761\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m anthropic.BadRequestError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m   1762\u001B[39m     _handle_anthropic_bad_request(e)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\github\\llm\\02langchain\\.venv\\Lib\\site-packages\\langchain_anthropic\\chat_models.py:1619\u001B[39m, in \u001B[36mChatAnthropic._create\u001B[39m\u001B[34m(self, payload)\u001B[39m\n\u001B[32m   1617\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mbetas\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m payload:\n\u001B[32m   1618\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._client.beta.messages.create(**payload)\n\u001B[32m-> \u001B[39m\u001B[32m1619\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_client\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mpayload\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\github\\llm\\02langchain\\.venv\\Lib\\site-packages\\anthropic\\_utils\\_utils.py:282\u001B[39m, in \u001B[36mrequired_args.<locals>.inner.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    280\u001B[39m             msg = \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mMissing required argument: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquote(missing[\u001B[32m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    281\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[32m--> \u001B[39m\u001B[32m282\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\github\\llm\\02langchain\\.venv\\Lib\\site-packages\\anthropic\\resources\\messages\\messages.py:930\u001B[39m, in \u001B[36mMessages.create\u001B[39m\u001B[34m(self, max_tokens, messages, model, metadata, service_tier, stop_sequences, stream, system, temperature, thinking, tool_choice, tools, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001B[39m\n\u001B[32m    923\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m model \u001B[38;5;129;01min\u001B[39;00m DEPRECATED_MODELS:\n\u001B[32m    924\u001B[39m     warnings.warn(\n\u001B[32m    925\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mThe model \u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m is deprecated and will reach end-of-life on \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mDEPRECATED_MODELS[model]\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mPlease migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    926\u001B[39m         \u001B[38;5;167;01mDeprecationWarning\u001B[39;00m,\n\u001B[32m    927\u001B[39m         stacklevel=\u001B[32m3\u001B[39m,\n\u001B[32m    928\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m930\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    931\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m/v1/messages\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    932\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    933\u001B[39m \u001B[43m        \u001B[49m\u001B[43m{\u001B[49m\n\u001B[32m    934\u001B[39m \u001B[43m            \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmax_tokens\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    935\u001B[39m \u001B[43m            \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmessages\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    936\u001B[39m \u001B[43m            \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmodel\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    937\u001B[39m \u001B[43m            \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmetadata\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    938\u001B[39m \u001B[43m            \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mservice_tier\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mservice_tier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    939\u001B[39m \u001B[43m            \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstop_sequences\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop_sequences\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    940\u001B[39m \u001B[43m            \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstream\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    941\u001B[39m \u001B[43m            \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43msystem\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43msystem\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    942\u001B[39m \u001B[43m            \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtemperature\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    943\u001B[39m \u001B[43m            \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mthinking\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mthinking\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    944\u001B[39m \u001B[43m            \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtool_choice\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtool_choice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    945\u001B[39m \u001B[43m            \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtools\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    946\u001B[39m \u001B[43m            \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtop_k\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_k\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    947\u001B[39m \u001B[43m            \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtop_p\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    948\u001B[39m \u001B[43m        \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    949\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmessage_create_params\u001B[49m\u001B[43m.\u001B[49m\u001B[43mMessageCreateParamsStreaming\u001B[49m\n\u001B[32m    950\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\n\u001B[32m    951\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mmessage_create_params\u001B[49m\u001B[43m.\u001B[49m\u001B[43mMessageCreateParamsNonStreaming\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    952\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    953\u001B[39m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    954\u001B[39m \u001B[43m        \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\n\u001B[32m    955\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    956\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m=\u001B[49m\u001B[43mMessage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    957\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    958\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m=\u001B[49m\u001B[43mStream\u001B[49m\u001B[43m[\u001B[49m\u001B[43mRawMessageStreamEvent\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    959\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\github\\llm\\02langchain\\.venv\\Lib\\site-packages\\anthropic\\_base_client.py:1324\u001B[39m, in \u001B[36mSyncAPIClient.post\u001B[39m\u001B[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[39m\n\u001B[32m   1310\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mpost\u001B[39m(\n\u001B[32m   1311\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   1312\u001B[39m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1319\u001B[39m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   1320\u001B[39m ) -> ResponseT | _StreamT:\n\u001B[32m   1321\u001B[39m     opts = FinalRequestOptions.construct(\n\u001B[32m   1322\u001B[39m         method=\u001B[33m\"\u001B[39m\u001B[33mpost\u001B[39m\u001B[33m\"\u001B[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001B[32m   1323\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m1324\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\github\\llm\\02langchain\\.venv\\Lib\\site-packages\\anthropic\\_base_client.py:1112\u001B[39m, in \u001B[36mSyncAPIClient.request\u001B[39m\u001B[34m(self, cast_to, options, stream, stream_cls)\u001B[39m\n\u001B[32m   1109\u001B[39m             err.response.read()\n\u001B[32m   1111\u001B[39m         log.debug(\u001B[33m\"\u001B[39m\u001B[33mRe-raising status error\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m1112\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m._make_status_error_from_response(err.response) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1114\u001B[39m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[32m   1116\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[33m\"\u001B[39m\u001B[33mcould not resolve response (should never happen)\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[31mNotFoundError\u001B[39m: Error code: 404 - {'error': {'message': 'Not found', 'type': 'invalid_request_error'}}"
     ]
    }
   ],
   "source": [
    "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "\n",
    "rate_limiter = InMemoryRateLimiter(\n",
    "    requests_per_second=1,  # 每1秒请求一次\n",
    "    check_every_n_seconds=0.1,  # 每100毫秒检查一次是否允许\n",
    "    max_bucket_size=10,  # 控制最大突发大小\n",
    ")\n",
    "#定义模型调用\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "model = ChatAnthropic(\n",
    "    model=\"claude-3-5-sonnet-20241022\",\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    base_url=os.environ.get(\"OPENAI_API_BASE\"),\n",
    "rate_limiter=rate_limiter #请求速率限制\n",
    ")\n",
    "#使用计时器来计算\n",
    "# 每次请求的时间间隔\n",
    "for _ in range(5):\n",
    "    tic = time.time()\n",
    "    model.invoke(\"hello\")\n",
    "    toc = time.time()\n",
    "    print(toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "id": "1982d7af-3e41-4c4a-a3c6-084a3c451bc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T09:21:34.528875Z",
     "start_time": "2025-10-01T09:21:25.386291Z"
    }
   },
   "source": [
    "from typing_extensions import Annotated, TypedDict\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import Optional, Union\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    temperature=0,\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    base_url=os.environ.get(\"OPENAI_API_BASE\"),\n",
    "    )\n",
    "\n",
    "class Joke(TypedDict):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "    setup: Annotated[str, ..., \"the setup of the joke\"]\n",
    "    punchline: Annotated[str, ..., \"The punchline of the joke\"]\n",
    "    rating: Annotated[Optional[int], None, \"How funny the joke is, from 1 to 10\"]\n",
    "\n",
    "structured_llm = llm.with_structured_output(Joke, method=\"function_calling\")\n",
    "for chunk in structured_llm.stream(\"给我讲一个关于设计师的笑话\"):\n",
    "    print(chunk)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'setup': ''}\n",
      "{'setup': 'Why'}\n",
      "{'setup': 'Why did'}\n",
      "{'setup': 'Why did the'}\n",
      "{'setup': 'Why did the designer'}\n",
      "{'setup': 'Why did the designer bring'}\n",
      "{'setup': 'Why did the designer bring a'}\n",
      "{'setup': 'Why did the designer bring a pencil'}\n",
      "{'setup': 'Why did the designer bring a pencil to'}\n",
      "{'setup': 'Why did the designer bring a pencil to bed'}\n",
      "{'setup': 'Why did the designer bring a pencil to bed?'}\n",
      "{'setup': 'Why did the designer bring a pencil to bed?', 'punchline': ''}\n",
      "{'setup': 'Why did the designer bring a pencil to bed?', 'punchline': 'To'}\n",
      "{'setup': 'Why did the designer bring a pencil to bed?', 'punchline': 'To draw'}\n",
      "{'setup': 'Why did the designer bring a pencil to bed?', 'punchline': 'To draw the'}\n",
      "{'setup': 'Why did the designer bring a pencil to bed?', 'punchline': 'To draw the curtains'}\n",
      "{'setup': 'Why did the designer bring a pencil to bed?', 'punchline': 'To draw the curtains!'}\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql1"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "%%sql\n",
   "id": "9d1e408dfbbfd3a0"
  },
  {
   "cell_type": "code",
   "id": "a3d84c18-ceeb-4277-8653-bdfb7841c43b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T13:46:35.735917Z",
     "start_time": "2025-10-01T13:46:27.559548Z"
    }
   },
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "class add(BaseModel):\n",
    "    \"\"\"Add two integers.\"\"\"\n",
    "    a: int = Field(..., description=\"The first integer\")\n",
    "    b: int = Field(..., description=\"The second integer\")\n",
    "\n",
    "class multiply(BaseModel):\n",
    "    \"\"\"Multiply two integers.\"\"\"\n",
    "    a: int = Field(..., description=\"The first integer\")\n",
    "    b: int = Field(..., description=\"The second integer\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0,\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    base_url=os.environ.get(\"OPENAI_API_BASE\"),\n",
    ")\n",
    "tools = [add, multiply]\n",
    "# 绑定工具\n",
    "llm_with_tools = llm.bind_tools(tools);\n",
    "query=\"3乘以12是多少？\"\n",
    "# 大模型处理“3乘以12”的时候调用了multiply类\n",
    "llm_with_tools.invoke(query).tool_calls"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 3, 'b': 12},\n",
       "  'id': 'call_kGIWv7XijyYEu67r61AoJW1Y',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
