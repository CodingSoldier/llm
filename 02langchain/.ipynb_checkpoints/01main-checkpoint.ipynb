{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02d15274",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好！我是一个人工智能助手，专门设计来帮助解答问题和提供信息。我可以协助你获取各种主题的资料，无论是科技、历史、文化还是日常生活等等。请随时向我提出问题，我会尽力为你提供帮助！', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 94, 'prompt_tokens': 14, 'total_tokens': 108, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-4', 'system_fingerprint': 'fp_5603ee5e2e', 'id': 'chatcmpl-CKlM8jJ8Ob39X0ydXaveDqOzKv4LV', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--3c77cbe2-544f-4fdf-a197-b3455e954efd-0', usage_metadata={'input_tokens': 14, 'output_tokens': 94, 'total_tokens': 108, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0,\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"), \n",
    "    base_url=os.getenv(\"OPENAI_API_BASE\")\n",
    ")\n",
    "llm.invoke(\"介绍你自己\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c4ed3bb-b907-4644-9cff-438146291eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是一个起名大师，请模仿示例起3个中国特色名字，比如：男孩经常被叫做狗剩,女孩经常被叫做翠花\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='男孩：铁柱、小强、石头\\n女孩：红梅、桂花、玉兰', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 66, 'total_tokens': 102, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-4', 'system_fingerprint': 'fp_5603ee5e2e', 'id': 'chatcmpl-CKl1R60RmwJksYfWBqskChYbUXHIG', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--c89fe63d-6688-44a2-9759-958037509deb-0', usage_metadata={'input_tokens': 66, 'output_tokens': 36, 'total_tokens': 102, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0,\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"), \n",
    "    base_url=os.getenv(\"OPENAI_API_BASE\")\n",
    ")\n",
    "prompt = PromptTemplate.from_template(\"你是一个起名大师，请模仿示例起3个{county}名字，比如：男孩经常被叫做{boy},女孩经常被叫做{girl}\")\n",
    "message=prompt.format(county=\"中国特色\", boy=\"狗剩\", girl=\"翠花\")\n",
    "print(message)\n",
    "\n",
    "llm.invoke(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe21c7c3-f14a-43ae-8d14-e0c92f37b29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是一个起名大师，请模仿示例起3个中国特色名字，比如：男孩经常被叫做狗剩,女孩经常被叫做翠花\n",
      "['当然可以！以下是三个具有中国特色的名字：\\n\\n1. 男孩：小虎\\n2. 女孩：梅花\\n3. 男孩：阿强\\n\\n这些名字都带有亲切感和传统色彩，符合中国特色的命名习惯。希望你喜欢！']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['当然可以！以下是三个具有中国特色的名字：\\n\\n1. 男孩：小虎\\n2. 女孩：梅花\\n3. 男孩：阿强\\n\\n这些名字都带有亲切感和传统色彩，符合中国特色的命名习惯。希望你喜欢！']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#起名大师，输出格式为一个数组\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import os\n",
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "#自定义类\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        if hasattr(text, 'content'):\n",
    "            text = text.content\n",
    "        t = text.strip().split(\",\")\n",
    "        print(t)\n",
    "        return t\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    temperature=0,\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"), \n",
    "    base_url=os.getenv(\"OPENAI_API_BASE\")\n",
    ")\n",
    "prompt = PromptTemplate.from_template(\"你是一个起名大师，请模仿示例起3个{county}名字，比如：男孩经常被叫做{boy},女孩经常被叫做{girl}\")\n",
    "message=prompt.format(county=\"中国广东特色\", boy=\"狗剩\", girl=\"翠花\")\n",
    "print(message)\n",
    "strs = llm.invoke(message)\n",
    "CommaSeparatedListOutputParser().parse(strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "259fe51d-8574-46cd-bb48-5f3945fbb0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始响应内容: 当然可以！以下是三个具有中国特色的名字：\n",
      "\n",
      "1. 男孩：小虎\n",
      "2. 女孩：梅花\n",
      "3. 男孩：阿强\n",
      "\n",
      "这些名字都带有一定的亲切感和传统色彩。希望你喜欢！\n",
      "解析后结果: ['当然可以！以下是三个具有中国特色的名字：\\n\\n1. 男孩：小虎\\n2. 女孩：梅花\\n3. 男孩：阿强\\n\\n这些名字都带有一定的亲切感和传统色彩。希望你喜欢！']\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI  # 确保正确导入 ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "\n",
    "# 自定义解析器\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    def parse(self, text):\n",
    "        if hasattr(text, 'content'):\n",
    "            text = text.content\n",
    "        return text.strip().split(\",\")\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "# 初始化 LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    temperature=0,\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"), \n",
    "    base_url=os.getenv(\"OPENAI_API_BASE\")\n",
    ")\n",
    " \n",
    "# 创建提示模板\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"你是一个起名大师，请模仿示例起3个{county}名字，比如：男孩经常被叫做{boy},女孩经常被叫做{girl}\"\n",
    ")\n",
    " \n",
    "# 生成具体输入\n",
    "message = prompt.format(\n",
    "    county=\"中国特色\",\n",
    "    boy=\"狗剩\",\n",
    "    girl=\"翠花\"\n",
    ")\n",
    " \n",
    "# 调用 LLM 并解析结果\n",
    "response = llm.invoke(message)\n",
    "parsed_result = CommaSeparatedListOutputParser().parse(response)\n",
    " \n",
    "print(\"原始响应内容:\", response.content)\n",
    "print(\"解析后结果:\", parsed_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "865648e0-2119-42d9-9414-8831a7c5ff01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event=on_chat_model_start | name=ChatOpenAI | data={'input': '介绍langchain'}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='Lang', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='Chain', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='是', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='一个', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='开', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='源', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='的', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='自', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='然', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='语', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='言', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='处理', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='（', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='N', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='LP', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='）', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='框', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='架', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='，', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='专', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='注', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='于', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='构', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='建', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='和', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='部', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='署', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='基', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='于', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='语', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='言', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='的', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='应', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='用', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='程序', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='。', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='它', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='提', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='供', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='了', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='一', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='系', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='列', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='工', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='具', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='和', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='库', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='，', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='使', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='开', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='发', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='者', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='能', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='够', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='轻', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='松', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='地', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='创建', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='、', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='训', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='练', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='和', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='部', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='署', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='与', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='人', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='类', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='进行', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='交', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='互', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='的', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='语', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='言', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='模', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='型', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='。', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='Lang', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='Chain', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='的', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='目', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='标', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='是', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='简', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='化', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='N', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='LP', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='应', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='用', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='的', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='开', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='发', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='过', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='程', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='，', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='使', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='其', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='更', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='加', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='高', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='效', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='和', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='可', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='扩', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='展', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='。', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='它', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='支', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='持', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='多', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='种', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='语', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='言', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='和', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='框', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='架', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='，', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='使', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='得', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='开', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='发', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='者', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='可以', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='根', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='据', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='自', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='己', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='的', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='需', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='求', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='选择', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='最', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='合', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='适', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='的', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='工', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='具', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='。', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4', 'system_fingerprint': 'fp_5603ee5e2e'}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_stream | name=ChatOpenAI | data={'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 12, 'output_tokens': 155, 'total_tokens': 167, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "event=on_chat_model_end | name=ChatOpenAI | data={'output': AIMessageChunk(content='LangChain是一个开源的自然语言处理（NLP）框架，专注于构建和部署基于语言的应用程序。它提供了一系列工具和库，使开发者能够轻松地创建、训练和部署与人类进行交互的语言模型。LangChain的目标是简化NLP应用的开发过程，使其更加高效和可扩展。它支持多种语言和框架，使得开发者可以根据自己的需求选择最合适的工具。', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4', 'system_fingerprint': 'fp_5603ee5e2e'}, id='run--5547a2d8-aace-4f4a-a1f1-39bfabaede77', usage_metadata={'input_tokens': 12, 'output_tokens': 155, 'total_tokens': 167, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import asyncio\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0,\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    base_url=os.environ.get(\"OPENAI_API_BASE\"),\n",
    ")\n",
    "question=\"langchain是什么？\"\n",
    "\n",
    "# invoke事件，同步调用LLM处理单个输入，返回完整响应。\n",
    "# llm.invoke(question)\n",
    "\n",
    "# stream事件，同步流式返回LLM的响应块（tokens），支持实时输出。\n",
    "# for chunk in llm.stream(question):\n",
    "#     print(chunk.content + \"|\")\n",
    "\n",
    "# batch 事件，批量处理多个输入，返回结果列表。\n",
    "# llm.batch([\"langchain作者是谁？\", \"langchain竞品有哪些？\"])\n",
    "\n",
    "# 异步事件流 astream_events。异步流式返回LLM执行过程中的事件（如开始、结束、中间步骤）。\n",
    "async for event in llm.astream_events(\"介绍langchain\", version=\"v2\"):\n",
    "    print(f\"event={event['event']} | name={event['name']} | data={event['data']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9d05153-861e-4e2f-9b5b-55ac9a7c684d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='Why do programmers prefer dark mode?', punchline='Because light attracts bugs!', rating=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    temperature=0,\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    base_url=os.environ.get(\"OPENAI_API_BASE\"),\n",
    "    )\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline to the joke\")\n",
    "    rating: Optional[int] = Field(\n",
    "        default=None, description=\"How funny the joke is, from 1 to 10\"\n",
    "    )\n",
    "structured_llm = llm.with_structured_output(Joke, method=\"function_calling\")\n",
    "structured_llm.invoke(\"给我讲一个关于程序员的笑话\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75c29092-f624-488e-91f8-a748f16f36ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'setup': ''}\n",
      "{'setup': '为'}\n",
      "{'setup': '为什'}\n",
      "{'setup': '为什么'}\n",
      "{'setup': '为什么程序'}\n",
      "{'setup': '为什么程序员'}\n",
      "{'setup': '为什么程序员喜'}\n",
      "{'setup': '为什么程序员喜欢'}\n",
      "{'setup': '为什么程序员喜欢黑'}\n",
      "{'setup': '为什么程序员喜欢黑暗'}\n",
      "{'setup': '为什么程序员喜欢黑暗？'}\n",
      "{'setup': '为什么程序员喜欢黑暗？', 'punchline': ''}\n",
      "{'setup': '为什么程序员喜欢黑暗？', 'punchline': '因'}\n",
      "{'setup': '为什么程序员喜欢黑暗？', 'punchline': '因为'}\n",
      "{'setup': '为什么程序员喜欢黑暗？', 'punchline': '因为光'}\n",
      "{'setup': '为什么程序员喜欢黑暗？', 'punchline': '因为光会'}\n",
      "{'setup': '为什么程序员喜欢黑暗？', 'punchline': '因为光会产'}\n",
      "{'setup': '为什么程序员喜欢黑暗？', 'punchline': '因为光会产生'}\n",
      "{'setup': '为什么程序员喜欢黑暗？', 'punchline': '因为光会产生bug'}\n",
      "{'setup': '为什么程序员喜欢黑暗？', 'punchline': '因为光会产生bug！'}\n"
     ]
    }
   ],
   "source": [
    "from typing_extensions import Annotated, TypedDict\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import Optional, Union\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    temperature=0,\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    base_url=os.environ.get(\"OPENAI_API_BASE\"),\n",
    "    )\n",
    "\n",
    "class Joke(TypedDict):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "    setup: Annotated[str, ..., \"the setup of the joke\"]\n",
    "    punchline: Annotated[str, ..., \"The punchline of the joke\"]\n",
    "    rating: Annotated[Optional[int], None, \"How funny the joke is, from 1 to 10\"]\n",
    "\n",
    "structured_llm = llm.with_structured_output(Joke, method=\"function_calling\")\n",
    "for chunk in structured_llm.stream(\"给我讲一个关于程序员的笑话\"):\n",
    "    print(chunk)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b961d642-95c2-456f-9fa3-db245af793a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'message': 'Not found', 'type': 'invalid_request_error'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFoundError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m5\u001b[39m):\n\u001b[32m     26\u001b[39m     tic = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhello\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     toc = time.time()\n\u001b[32m     29\u001b[39m     \u001b[38;5;28mprint\u001b[39m(toc - tic)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\github\\llm\\02langchain\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:395\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    385\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    390\u001b[39m     **kwargs: Any,\n\u001b[32m    391\u001b[39m ) -> BaseMessage:\n\u001b[32m    392\u001b[39m     config = ensure_config(config)\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    394\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    405\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\github\\llm\\02langchain\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1023\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1014\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1020\u001b[39m     **kwargs: Any,\n\u001b[32m   1021\u001b[39m ) -> LLMResult:\n\u001b[32m   1022\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\github\\llm\\02langchain\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:840\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    837\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    838\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    839\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m840\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    846\u001b[39m         )\n\u001b[32m    847\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    848\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\github\\llm\\02langchain\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1089\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1087\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1088\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1089\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1090\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1091\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1093\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\github\\llm\\02langchain\\.venv\\Lib\\site-packages\\langchain_anthropic\\chat_models.py:1760\u001b[39m, in \u001b[36mChatAnthropic._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1758\u001b[39m payload = \u001b[38;5;28mself\u001b[39m._get_request_payload(messages, stop=stop, **kwargs)\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1760\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1761\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m anthropic.BadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1762\u001b[39m     _handle_anthropic_bad_request(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\github\\llm\\02langchain\\.venv\\Lib\\site-packages\\langchain_anthropic\\chat_models.py:1619\u001b[39m, in \u001b[36mChatAnthropic._create\u001b[39m\u001b[34m(self, payload)\u001b[39m\n\u001b[32m   1617\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m payload:\n\u001b[32m   1618\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.beta.messages.create(**payload)\n\u001b[32m-> \u001b[39m\u001b[32m1619\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\github\\llm\\02langchain\\.venv\\Lib\\site-packages\\anthropic\\_utils\\_utils.py:282\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    280\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    281\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\github\\llm\\02langchain\\.venv\\Lib\\site-packages\\anthropic\\resources\\messages\\messages.py:930\u001b[39m, in \u001b[36mMessages.create\u001b[39m\u001b[34m(self, max_tokens, messages, model, metadata, service_tier, stop_sequences, stream, system, temperature, thinking, tool_choice, tools, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    923\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m DEPRECATED_MODELS:\n\u001b[32m    924\u001b[39m     warnings.warn(\n\u001b[32m    925\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe model \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is deprecated and will reach end-of-life on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDEPRECATED_MODELS[model]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPlease migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    926\u001b[39m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m    927\u001b[39m         stacklevel=\u001b[32m3\u001b[39m,\n\u001b[32m    928\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/v1/messages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop_sequences\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthinking\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mthinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_k\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMessageCreateParamsStreaming\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMessageCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mRawMessageStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\github\\llm\\02langchain\\.venv\\Lib\\site-packages\\anthropic\\_base_client.py:1324\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1310\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1311\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1312\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1319\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1320\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1321\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1322\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1323\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\github\\llm\\02langchain\\.venv\\Lib\\site-packages\\anthropic\\_base_client.py:1112\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1109\u001b[39m             err.response.read()\n\u001b[32m   1111\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1112\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1114\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1116\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mNotFoundError\u001b[39m: Error code: 404 - {'error': {'message': 'Not found', 'type': 'invalid_request_error'}}"
     ]
    }
   ],
   "source": [
    "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "\n",
    "rate_limiter = InMemoryRateLimiter(\n",
    "    requests_per_second=1,  # 每1秒请求一次\n",
    "    check_every_n_seconds=0.1,  # 每100毫秒检查一次是否允许\n",
    "    max_bucket_size=10,  # 控制最大突发大小\n",
    ")\n",
    "#定义模型调用\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "model = ChatAnthropic(\n",
    "    model=\"claude-3-5-sonnet-20241022\",\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    base_url=os.environ.get(\"OPENAI_API_BASE\"),\n",
    "rate_limiter=rate_limiter #请求速率限制\n",
    ")\n",
    "#使用计时器来计算\n",
    "# 每次请求的时间间隔\n",
    "for _ in range(5):\n",
    "    tic = time.time()\n",
    "    model.invoke(\"hello\")\n",
    "    toc = time.time()\n",
    "    print(toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1982d7af-3e41-4c4a-a3c6-084a3c451bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_anthropic\n",
      "  Obtaining dependency information for langchain_anthropic from https://files.pythonhosted.org/packages/21/de/3b553f9a173dc6b57ec66f727ffed5131119b0ac23654e8c304decb8ded1/langchain_anthropic-0.3.21-py3-none-any.whl.metadata\n",
      "  Downloading langchain_anthropic-0.3.21-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting anthropic<1.0.0,>=0.69.0 (from langchain_anthropic)\n",
      "  Obtaining dependency information for anthropic<1.0.0,>=0.69.0 from https://files.pythonhosted.org/packages/9b/38/75129688de5637eb5b383e5f2b1570a5cc3aecafa4de422da8eea4b90a6c/anthropic-0.69.0-py3-none-any.whl.metadata\n",
      "  Downloading anthropic-0.69.0-py3-none-any.whl.metadata (28 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=0.3.76 in e:\\github\\llm\\02langchain\\.venv\\lib\\site-packages (from langchain_anthropic) (0.3.76)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in e:\\github\\llm\\02langchain\\.venv\\lib\\site-packages (from langchain_anthropic) (2.11.9)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in e:\\github\\llm\\02langchain\\.venv\\lib\\site-packages (from anthropic<1.0.0,>=0.69.0->langchain_anthropic) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in e:\\github\\llm\\02langchain\\.venv\\lib\\site-packages (from anthropic<1.0.0,>=0.69.0->langchain_anthropic) (1.9.0)\n",
      "Collecting docstring-parser<1,>=0.15 (from anthropic<1.0.0,>=0.69.0->langchain_anthropic)\n",
      "  Obtaining dependency information for docstring-parser<1,>=0.15 from https://files.pythonhosted.org/packages/55/e2/2537ebcff11c1ee1ff17d8d0b6f4db75873e3b0fb32c2d4a2ee31ecb310a/docstring_parser-0.17.0-py3-none-any.whl.metadata\n",
      "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in e:\\github\\llm\\02langchain\\.venv\\lib\\site-packages (from anthropic<1.0.0,>=0.69.0->langchain_anthropic) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in e:\\github\\llm\\02langchain\\.venv\\lib\\site-packages (from anthropic<1.0.0,>=0.69.0->langchain_anthropic) (0.11.0)\n",
      "Requirement already satisfied: sniffio in e:\\github\\llm\\02langchain\\.venv\\lib\\site-packages (from anthropic<1.0.0,>=0.69.0->langchain_anthropic) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in e:\\github\\llm\\02langchain\\.venv\\lib\\site-packages (from anthropic<1.0.0,>=0.69.0->langchain_anthropic) (4.15.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in e:\\github\\llm\\02langchain\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.76->langchain_anthropic) (0.3.45)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in e:\\github\\llm\\02langchain\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.76->langchain_anthropic) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in e:\\github\\llm\\02langchain\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.76->langchain_anthropic) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in e:\\github\\llm\\02langchain\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.76->langchain_anthropic) (6.0.3)\n",
      "Requirement already satisfied: packaging>=23.2 in e:\\github\\llm\\02langchain\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.76->langchain_anthropic) (25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\github\\llm\\02langchain\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain_anthropic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in e:\\github\\llm\\02langchain\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain_anthropic) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in e:\\github\\llm\\02langchain\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain_anthropic) (0.4.1)\n",
      "Requirement already satisfied: idna>=2.8 in e:\\github\\llm\\02langchain\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->anthropic<1.0.0,>=0.69.0->langchain_anthropic) (3.10)\n",
      "Requirement already satisfied: certifi in e:\\github\\llm\\02langchain\\.venv\\lib\\site-packages (from httpx<1,>=0.25.0->anthropic<1.0.0,>=0.69.0->langchain_anthropic) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\github\\llm\\02langchain\\.venv\\lib\\site-packages (from httpx<1,>=0.25.0->anthropic<1.0.0,>=0.69.0->langchain_anthropic) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in e:\\github\\llm\\02langchain\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic<1.0.0,>=0.69.0->langchain_anthropic) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in e:\\github\\llm\\02langchain\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.76->langchain_anthropic) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in e:\\github\\llm\\02langchain\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain_anthropic) (3.11.3)\n",
      "Requirement already satisfied: requests<3,>=2 in e:\\github\\llm\\02langchain\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain_anthropic) (2.32.5)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in e:\\github\\llm\\02langchain\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain_anthropic) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in e:\\github\\llm\\02langchain\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain_anthropic) (0.23.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in e:\\github\\llm\\02langchain\\.venv\\lib\\site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain_anthropic) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\github\\llm\\02langchain\\.venv\\lib\\site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain_anthropic) (2.5.0)\n",
      "Downloading langchain_anthropic-0.3.21-py3-none-any.whl (32 kB)\n",
      "Downloading anthropic-0.69.0-py3-none-any.whl (337 kB)\n",
      "   ---------------------------------------- 0.0/337.3 kB ? eta -:--:--\n",
      "   ------- -------------------------------- 61.4/337.3 kB 3.2 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 92.2/337.3 kB 1.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 194.6/337.3 kB 2.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 235.5/337.3 kB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 307.2/337.3 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 337.3/337.3 kB 1.5 MB/s eta 0:00:00\n",
      "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: docstring-parser, anthropic, langchain_anthropic\n",
      "Successfully installed anthropic-0.69.0 docstring-parser-0.17.0 langchain_anthropic-0.3.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain_anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d84c18-ceeb-4277-8653-bdfb7841c43b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
